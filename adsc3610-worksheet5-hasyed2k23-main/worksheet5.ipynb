{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "645b0f98-530b-436c-82a8-42e420148985",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Worksheet 5: Spark DataFrame manipulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38de8cef-789d-4127-85f9-ae49d941454e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Import the worksheet5.ipynb to databricks community edition\n",
    "\n",
    "- For this worksheet5, I'd like you to upload the ipynb to databricks community edition and work on the assignment there.\n",
    "- After finish the assignment, you can download it to your github repo, and push the changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f81bab9f-1327-4b73-a6f9-d5d3373d5d4b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Exercise 1: Creating a Spark DataFrame from a List with Predefined Data Types\n",
    "\n",
    "#### Instructions:\n",
    "1. **Import necessary Spark libraries.**\n",
    "2. **Define a list of book data.** The list should contain tuples with the following information: Title (String), Author (String), Year (Integer), and Rating (Float).\n",
    "3. **Define the schema with predefined data types.** Use `StructType` and `StructField` to define the schema.\n",
    "4. **Create a DataFrame using the list and schema.** Use `spark.createDataFrame(data, schema)`.\n",
    "5. **Show the DataFrame.** Use `df.show()` to display the DataFrame.\n",
    "\n",
    "#### Example Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85c83ec2-71d6-41f5-8d79-1836a1e869a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"The Catcher in the Rye\", \"J.D. Salinger\", 1951, 4.0),\n",
    "    (\"To Kill a Mockingbird\", \"Harper Lee\", 1960, 4.3),\n",
    "    (\"1984\", \"George Orwell\", 1949, 4.2),\n",
    "    (\"Pride and Prejudice\", \"Jane Austen\", 1813, 4.3),\n",
    "    (\"The Great Gatsby\", \"F. Scott Fitzgerald\", 1925, 3.9),\n",
    "    (\"Moby-Dick\", \"Herman Melville\", 1851, 3.5),\n",
    "    (\"War and Peace\", \"Leo Tolstoy\", 1869, 4.1),\n",
    "    (\"The Odyssey\", \"Homer\", -800, 3.8),\n",
    "    (\"Ulysses\", \"James Joyce\", 1922, 3.7),\n",
    "    (\"The Divine Comedy\", \"Dante Alighieri\", 1320, 4.2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56f94c3a-6a60-4205-844b-5b08244f3d31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7eab40f3-d463-4217-a907-03f94ec6848b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Exercise 2: Exploring a Spark DataFrame\n",
    "\n",
    "#### Instructions:\n",
    "1. **Print the schema** of the DataFrame to see the column names and data types.\n",
    "2. **Show the column names** of the DataFrame.\n",
    "3. **Show the data types** of each column in the DataFrame.\n",
    "4. **Take the first `n` rows** of the DataFrame and display them.\n",
    "5. **Sample `n` rows** from the DataFrame and display them.\n",
    "\n",
    "Fill in the code to complete the exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24bfe9d6-516b-4242-9dcb-141d1948a403",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Assuming the DataFrame 'df' was already created from the previous exercise\n",
    "\n",
    "# Step 1: Print the schema of the DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e17bab3d-fd6b-4a9d-a9fe-8c73c04470f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Show the column names of the DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0179b09e-3634-42e3-9b0f-9bab870663f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Show the data types of each column in the DataFrame\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68c1579a-3f30-4ad8-9e83-a3c2d14c1ee6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Take the first n rows of the DataFrame and display them\n",
    "n = 5  # You can change this value as needed\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "182ee23d-999a-471a-95fc-42e979b80bb8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Sample n rows from the DataFrame and display them\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "801f0fde-230d-4275-a6ae-da33dbf3fad9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Exercise 3: Filtering, Selecting, and Ordering Data in a Spark DataFrame\n",
    "\n",
    "#### Instructions:\n",
    "1. **Filter** the DataFrame to include only books with a rating greater than 4.0.\n",
    "2. **Select** only the \"Title\" and \"Author\" columns.\n",
    "3. **Order** the DataFrame by \"Year\" in ascending order.\n",
    "4. **Show the resulting DataFrame.**\n",
    "\n",
    "Fill in the code to complete the exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7f449ca-002f-4f77-b678-4dd6ad9c5010",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "361832b5-be1a-48f2-8fab-28da24a2dce5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Exercise 4: String Manipulations in a Spark DataFrame\n",
    "\n",
    "#### Instructions:\n",
    "1. **Create a new column** that converts the \"Title\" column to uppercase.\n",
    "2. **Create a new column** that extracts the first word from the \"Title\" column.\n",
    "3. **Filter** the DataFrame to include only books where the \"Author\" column contains the letter 'e'.\n",
    "4. **Show** the resulting DataFrame.\n",
    "\n",
    "Fill in the code to complete the exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "170a159e-8cd7-4006-969a-db3e4415c8cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import upper, split, col\n",
    "\n",
    "# Assuming the DataFrame 'df' was already created from the previous exercise\n",
    "\n",
    "# Step 1: Create a new column that converts the \"Title\" column to uppercase\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b32d01c-db2a-4cb3-a4c0-866774f0146b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Create a new column that extracts the first word from the \"Title\" column\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb921e4f-1c7f-44c6-aeb1-5b6036840baf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Filter the DataFrame to include only books where the \"Author\" column contains the letter 'e'\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b077fee8-a075-44bd-882a-fb7f034668e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Show the resulting DataFrame\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42e94101-a448-4347-a738-16f1c12409c0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Exercise 5: Aggregations in a Spark DataFrame\n",
    "\n",
    "#### Instructions:\n",
    "1. **Calculate the average rating** of all books.\n",
    "2. **Calculate the maximum rating** of all books.\n",
    "3. **Calculate the minimum rating** of all books.\n",
    "4. **Group by the \"Author\"** and calculate the average rating for each author.\n",
    "5. **Show** the resulting DataFrames.\n",
    "\n",
    "Fill in the code to complete the exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "955909b2-1b7b-4aa5-b9f6-ca631acf6a1a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, max, min\n",
    "\n",
    "# Assuming the DataFrame 'df' was already created from the previous exercise\n",
    "\n",
    "# Step 1: Calculate the average rating of all books\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 2: Calculate the maximum rating of all books\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 3: Calculate the minimum rating of all books\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 4: Group by the \"Author\" and calculate the average rating for each author\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 5: Show the resulting DataFrame\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c5ee89e-618f-4832-bbc6-c1d44e36d57c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Exercise 6: Column Manipulations in a Spark DataFrame\n",
    "\n",
    "#### Instructions:\n",
    "1. **Add a new column** that indicates whether the book was published in the 20th century (1901-2000).\n",
    "2. **Rename the \"Rating\" column** to \"Book_Rating\".\n",
    "3. **Drop the \"Year\" column** from the DataFrame.\n",
    "4. **Show** the resulting DataFrame.\n",
    "\n",
    "Fill in the code to complete the exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b8bf96d-f4d9-4368-92d8-87222ce846d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Assuming the DataFrame 'df' was already created from the previous exercise\n",
    "\n",
    "# Step 1: Add a new column that indicates whether the book was published in the 20th century (1901-2000)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 2: Rename the \"Rating\" column to \"Book_Rating\"\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 3: Drop the \"Year\" column from the DataFrame\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 4: Show the resulting DataFrame\n",
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "worksheet5",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "adsc_3610",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
