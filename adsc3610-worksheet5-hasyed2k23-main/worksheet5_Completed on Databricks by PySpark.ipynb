{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "645b0f98-530b-436c-82a8-42e420148985",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Worksheet 5: Spark DataFrame manipulations ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38de8cef-789d-4127-85f9-ae49d941454e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Import the worksheet5.ipynb to databricks community edition\n",
    "\n",
    "- For this worksheet5, I'd like you to upload the ipynb to databricks community edition and work on the assignment there.\n",
    "- After finish the assignment, you can download it to your github repo, and push the changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f81bab9f-1327-4b73-a6f9-d5d3373d5d4b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Exercise 1: Creating a Spark DataFrame from a List with Predefined Data Types\n",
    "\n",
    "#### Instructions:\n",
    "1. **Import necessary Spark libraries.**\n",
    "2. **Define a list of book data.** The list should contain tuples with the following information: Title (String), Author (String), Year (Integer), and Rating (Float).\n",
    "3. **Define the schema with predefined data types.** Use `StructType` and `StructField` to define the schema.\n",
    "4. **Create a DataFrame using the list and schema.** Use `spark.createDataFrame(data, schema)`.\n",
    "5. **Show the DataFrame.** Use `df.show()` to display the DataFrame.\n",
    "\n",
    "#### Example Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85c83ec2-71d6-41f5-8d79-1836a1e869a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"The Catcher in the Rye\", \"J.D. Salinger\", 1951, 4.0),\n",
    "    (\"To Kill a Mockingbird\", \"Harper Lee\", 1960, 4.3),\n",
    "    (\"1984\", \"George Orwell\", 1949, 4.2),\n",
    "    (\"Pride and Prejudice\", \"Jane Austen\", 1813, 4.3),\n",
    "    (\"The Great Gatsby\", \"F. Scott Fitzgerald\", 1925, 3.9),\n",
    "    (\"Moby-Dick\", \"Herman Melville\", 1851, 3.5),\n",
    "    (\"War and Peace\", \"Leo Tolstoy\", 1869, 4.1),\n",
    "    (\"The Odyssey\", \"Homer\", -800, 3.8),\n",
    "    (\"Ulysses\", \"James Joyce\", 1922, 3.7),\n",
    "    (\"The Divine Comedy\", \"Dante Alighieri\", 1320, 4.2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56f94c3a-6a60-4205-844b-5b08244f3d31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+----+------+\n",
      "|               Title|             Author|Year|Rating|\n",
      "+--------------------+-------------------+----+------+\n",
      "|The Catcher in th...|      J.D. Salinger|1951|   4.0|\n",
      "|To Kill a Mocking...|         Harper Lee|1960|  4.27|\n",
      "|                1984|      George Orwell|1949|  4.17|\n",
      "| Pride and Prejudice|        Jane Austen|1813|  4.26|\n",
      "|    The Great Gatsby|F. Scott Fitzgerald|1925|  3.91|\n",
      "+--------------------+-------------------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 1: Import necessary Spark libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "\n",
    "# Step 2: Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"BookDataFrame\").getOrCreate()\n",
    "\n",
    "# Step 3: Define a list of book data (Title, Author, Year, Rating)\n",
    "book_data = [\n",
    "    (\"The Catcher in the Rye\", \"J.D. Salinger\", 1951, 4.0),\n",
    "    (\"To Kill a Mockingbird\", \"Harper Lee\", 1960, 4.27),\n",
    "    (\"1984\", \"George Orwell\", 1949, 4.17),\n",
    "    (\"Pride and Prejudice\", \"Jane Austen\", 1813, 4.26),\n",
    "    (\"The Great Gatsby\", \"F. Scott Fitzgerald\", 1925, 3.91)\n",
    "]\n",
    "\n",
    "# Step 4: Define the schema using StructType and StructField\n",
    "schema = StructType([\n",
    "    StructField(\"Title\", StringType(), True),\n",
    "    StructField(\"Author\", StringType(), True),\n",
    "    StructField(\"Year\", IntegerType(), True),\n",
    "    StructField(\"Rating\", FloatType(), True)\n",
    "])\n",
    "\n",
    "# Step 5: Create a DataFrame using the list and schema\n",
    "df = spark.createDataFrame(book_data, schema)\n",
    "\n",
    "# Step 6: Show the DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7eab40f3-d463-4217-a907-03f94ec6848b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Exercise 2: Exploring a Spark DataFrame\n",
    "\n",
    "#### Instructions:\n",
    "1. **Print the schema** of the DataFrame to see the column names and data types.\n",
    "2. **Show the column names** of the DataFrame.\n",
    "3. **Show the data types** of each column in the DataFrame.\n",
    "4. **Take the first `n` rows** of the DataFrame and display them.\n",
    "5. **Sample `n` rows** from the DataFrame and display them.\n",
    "\n",
    "Fill in the code to complete the exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24bfe9d6-516b-4242-9dcb-141d1948a403",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Author: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming the DataFrame 'df' was already created from the previous exercise\n",
    "\n",
    "# Step 1: Print the schema of the DataFrame\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Step 7: Print the schema of the DataFrame to see the column names and data types\n",
    "df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e17bab3d-fd6b-4a9d-a9fe-8c73c04470f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: ['Title', 'Author', 'Year', 'Rating']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Show the column names of the DataFrame\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"Column Names:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0179b09e-3634-42e3-9b0f-9bab870663f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types of Each Column:\n",
      "Title: string\n",
      "Author: string\n",
      "Year: int\n",
      "Rating: float\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Show the data types of each column in the DataFrame\n",
    "# YOUR CODE HERE\n",
    "print(\"Data Types of Each Column:\")\n",
    "for col_name, col_type in df.dtypes:\n",
    "    print(f\"{col_name}: {col_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68c1579a-3f30-4ad8-9e83-a3c2d14c1ee6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 4 Rows:\n",
      "+--------------------+-------------+----+------+\n",
      "|               Title|       Author|Year|Rating|\n",
      "+--------------------+-------------+----+------+\n",
      "|The Catcher in th...|J.D. Salinger|1951|   4.0|\n",
      "|To Kill a Mocking...|   Harper Lee|1960|  4.27|\n",
      "|                1984|George Orwell|1949|  4.17|\n",
      "| Pride and Prejudice|  Jane Austen|1813|  4.26|\n",
      "+--------------------+-------------+----+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Take the first n rows of the DataFrame and display them \n",
    "# You can change this value as needed\n",
    "# YOUR CODE HERE\n",
    "n = 4\n",
    "print(\"First 4 Rows:\")\n",
    "df.show(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "182ee23d-999a-471a-95fc-42e979b80bb8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Sample of 2 Rows:\n",
      "+--------------------+-------------+----+------+\n",
      "|               Title|       Author|Year|Rating|\n",
      "+--------------------+-------------+----+------+\n",
      "|To Kill a Mocking...|   Harper Lee|1960|  4.27|\n",
      "|                1984|George Orwell|1949|  4.17|\n",
      "+--------------------+-------------+----+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Sample n rows from the DataFrame and display them\n",
    "# YOUR CODE HERE\n",
    "print(\"Random Sample of 2 Rows:\")\n",
    "n_r = 2\n",
    "df.sample(withReplacement=False, fraction=0.4).show(n_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "801f0fde-230d-4275-a6ae-da33dbf3fad9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Exercise 3: Filtering, Selecting, and Ordering Data in a Spark DataFrame\n",
    "\n",
    "#### Instructions:\n",
    "1. **Filter** the DataFrame to include only books with a rating greater than 4.0.\n",
    "2. **Select** only the \"Title\" and \"Author\" columns.\n",
    "3. **Order** the DataFrame by \"Year\" in ascending order.\n",
    "4. **Show the resulting DataFrame.**\n",
    "\n",
    "Fill in the code to complete the exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7f449ca-002f-4f77-b678-4dd6ad9c5010",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+----+------+\n",
      "|               Title|       Author|Year|Rating|\n",
      "+--------------------+-------------+----+------+\n",
      "| Pride and Prejudice|  Jane Austen|1813|  4.26|\n",
      "|                1984|George Orwell|1949|  4.17|\n",
      "|To Kill a Mocking...|   Harper Lee|1960|  4.27|\n",
      "+--------------------+-------------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "#Filter the DataFrame to include only books with a rating greater than 4.0\n",
    "filtered_df = df.filter(df[\"Rating\"] > 4.0)\n",
    "\n",
    "#Select only the \"Title\" and \"Author\" columns\n",
    "selected_df = filtered_df.select(\"Title\", \"Author\")\n",
    "\n",
    "#Order the DataFrame by \"Year\" in ascending order\n",
    "ordered_df = filtered_df.orderBy(\"Year\", ascending=True)\n",
    "\n",
    "#Show the resulting DataFrame\n",
    "ordered_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "361832b5-be1a-48f2-8fab-28da24a2dce5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Exercise 4: String Manipulations in a Spark DataFrame\n",
    "\n",
    "#### Instructions:\n",
    "1. **Create a new column** that converts the \"Title\" column to uppercase.\n",
    "2. **Create a new column** that extracts the first word from the \"Title\" column.\n",
    "3. **Filter** the DataFrame to include only books where the \"Author\" column contains the letter 'e'.\n",
    "4. **Show** the resulting DataFrame.\n",
    "\n",
    "Fill in the code to complete the exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "170a159e-8cd7-4006-969a-db3e4415c8cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+----+------+\n",
      "|               Title|             Author|Year|Rating|\n",
      "+--------------------+-------------------+----+------+\n",
      "|The Catcher in th...|      J.D. Salinger|1951|   4.0|\n",
      "|To Kill a Mocking...|         Harper Lee|1960|  4.27|\n",
      "|                1984|      George Orwell|1949|  4.17|\n",
      "| Pride and Prejudice|        Jane Austen|1813|  4.26|\n",
      "|    The Great Gatsby|F. Scott Fitzgerald|1925|  3.91|\n",
      "+--------------------+-------------------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import upper, split, col\n",
    "\n",
    "# Assuming the DataFrame 'df' was already created from the previous exercise\n",
    "\n",
    "# Step 1: Create a new column that converts the \"Title\" column to uppercase\n",
    "df_with_upper_title = df.withColumn(\"Uppercase_Title\", upper(df[\"Title\"]))\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b32d01c-db2a-4cb3-a4c0-866774f0146b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+----+------+\n",
      "|               Title|             Author|Year|Rating|\n",
      "+--------------------+-------------------+----+------+\n",
      "|The Catcher in th...|      J.D. Salinger|1951|   4.0|\n",
      "|To Kill a Mocking...|         Harper Lee|1960|  4.27|\n",
      "|                1984|      George Orwell|1949|  4.17|\n",
      "| Pride and Prejudice|        Jane Austen|1813|  4.26|\n",
      "|    The Great Gatsby|F. Scott Fitzgerald|1925|  3.91|\n",
      "+--------------------+-------------------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Create a new column that extracts the first word from the \"Title\" column\n",
    "# YOUR CODE HERE\n",
    "df_with_first_word = df_with_upper_title.withColumn(\"First_Word\", split(df[\"Title\"], \" \")[0])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb921e4f-1c7f-44c6-aeb1-5b6036840baf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Filter the DataFrame to include only books where the \"Author\" column contains the letter 'e'\n",
    "# YOUR CODE HERE\n",
    "filtered_df_by_author = df_with_first_word.filter(df[\"Author\"].contains(\"e\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b077fee8-a075-44bd-882a-fb7f034668e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+----+------+--------------------+----------+\n",
      "|               Title|             Author|Year|Rating|     Uppercase_Title|First_Word|\n",
      "+--------------------+-------------------+----+------+--------------------+----------+\n",
      "|The Catcher in th...|      J.D. Salinger|1951|   4.0|THE CATCHER IN TH...|       The|\n",
      "|To Kill a Mocking...|         Harper Lee|1960|  4.27|TO KILL A MOCKING...|        To|\n",
      "|                1984|      George Orwell|1949|  4.17|                1984|      1984|\n",
      "| Pride and Prejudice|        Jane Austen|1813|  4.26| PRIDE AND PREJUDICE|     Pride|\n",
      "|    The Great Gatsby|F. Scott Fitzgerald|1925|  3.91|    THE GREAT GATSBY|       The|\n",
      "+--------------------+-------------------+----+------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Show the resulting DataFrame\n",
    "# YOUR CODE HERE\n",
    "filtered_df_by_author.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42e94101-a448-4347-a738-16f1c12409c0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Exercise 5: Aggregations in a Spark DataFrame\n",
    "\n",
    "#### Instructions:\n",
    "1. **Calculate the average rating** of all books.\n",
    "2. **Calculate the maximum rating** of all books.\n",
    "3. **Calculate the minimum rating** of all books.\n",
    "4. **Group by the \"Author\"** and calculate the average rating for each author.\n",
    "5. **Show** the resulting DataFrames.\n",
    "\n",
    "Fill in the code to complete the exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "955909b2-1b7b-4aa5-b9f6-ca631acf6a1a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Rating of All Books:\n",
      "+-----------------+\n",
      "|   Average_Rating|\n",
      "+-----------------+\n",
      "|4.122000074386596|\n",
      "+-----------------+\n",
      "\n",
      "Maximum Rating of All Books:\n",
      "+--------------+\n",
      "|Maximum_Rating|\n",
      "+--------------+\n",
      "|          4.27|\n",
      "+--------------+\n",
      "\n",
      "Minimum Rating of All Books:\n",
      "+--------------+\n",
      "|Minimum_Rating|\n",
      "+--------------+\n",
      "|          3.91|\n",
      "+--------------+\n",
      "\n",
      "Average Rating for Each Author:\n",
      "+-------------------+------------------+\n",
      "|             Author|    Average_Rating|\n",
      "+-------------------+------------------+\n",
      "|      J.D. Salinger|               4.0|\n",
      "|         Harper Lee| 4.269999980926514|\n",
      "|      George Orwell| 4.170000076293945|\n",
      "|        Jane Austen| 4.260000228881836|\n",
      "|F. Scott Fitzgerald|3.9100000858306885|\n",
      "+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, max, min\n",
    "\n",
    "# Step 1: Calculate the average rating of all books\n",
    "# YOUR CODE HERE\n",
    "average_rating = df.agg(avg(\"Rating\").alias(\"Average_Rating\"))\n",
    "\n",
    "# Step 2: Calculate the maximum rating of all books\n",
    "# YOUR CODE HERE\n",
    "max_rating = df.agg(max(\"Rating\").alias(\"Maximum_Rating\"))\n",
    "\n",
    "# Step 3: Calculate the minimum rating of all books\n",
    "# YOUR CODE HERE\n",
    "min_rating = df.agg(min(\"Rating\").alias(\"Minimum_Rating\"))\n",
    "\n",
    "# Step 4: Group by the \"Author\" and calculate the average rating for each author\n",
    "# YOUR CODE HERE\n",
    "avg_rating_per_author = df.groupBy(\"Author\").agg(avg(\"Rating\").alias(\"Average_Rating\"))\n",
    "\n",
    "# Step 5: Show the resulting DataFrame\n",
    "# YOUR CODE HERE\n",
    "print(\"Average Rating of All Books:\")\n",
    "average_rating.show()\n",
    "\n",
    "print(\"Maximum Rating of All Books:\")\n",
    "max_rating.show()\n",
    "\n",
    "print(\"Minimum Rating of All Books:\")\n",
    "min_rating.show()\n",
    "\n",
    "print(\"Average Rating for Each Author:\")\n",
    "avg_rating_per_author.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c5ee89e-618f-4832-bbc6-c1d44e36d57c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Exercise 6: Column Manipulations in a Spark DataFrame\n",
    "\n",
    "#### Instructions:\n",
    "1. **Add a new column** that indicates whether the book was published in the 20th century (1901-2000).\n",
    "2. **Rename the \"Rating\" column** to \"Book_Rating\".\n",
    "3. **Drop the \"Year\" column** from the DataFrame.\n",
    "4. **Show** the resulting DataFrame.\n",
    "\n",
    "Fill in the code to complete the exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b8bf96d-f4d9-4368-92d8-87222ce846d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----------+-------------------------+\n",
      "|               Title|             Author|Book_Rating|Published_in_20th_Century|\n",
      "+--------------------+-------------------+-----------+-------------------------+\n",
      "|The Catcher in th...|      J.D. Salinger|        4.0|                     true|\n",
      "|To Kill a Mocking...|         Harper Lee|       4.27|                     true|\n",
      "|                1984|      George Orwell|       4.17|                     true|\n",
      "| Pride and Prejudice|        Jane Austen|       4.26|                    false|\n",
      "|    The Great Gatsby|F. Scott Fitzgerald|       3.91|                     true|\n",
      "+--------------------+-------------------+-----------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Assuming the DataFrame 'df' was already created from the previous exercise\n",
    "\n",
    "\n",
    "# Step 1: Add a new column that indicates whether the book was published in the 20th century (1901-2000)\n",
    "# YOUR CODE HERE\n",
    "df_with_century = df.withColumn(\"Published_in_20th_Century\", \n",
    "                                (col(\"Year\") >= 1901) & (col(\"Year\") <= 2000))\n",
    "\n",
    "# # Step 2: Rename the \"Rating\" column to \"Book_Rating\"\n",
    "# YOUR CODE HERE\n",
    "df_with_renamed_column = df_with_century.withColumnRenamed(\"Rating\", \"Book_Rating\")\n",
    "\n",
    "# Step 3: Drop the \"Year\" column from the DataFrame\n",
    "# YOUR CODE HERE\n",
    "df_final = df_with_renamed_column.drop(\"Year\")\n",
    "\n",
    "# Step 4: Show the resulting DataFrame\n",
    "# YOUR CODE HERE\n",
    "df_final.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "worksheet5",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
